{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff67e0-ed5b-4a9f-a2ac-ac3adffce934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((256,56,54)).to(devices[0])\n",
    "a = torch.randn((256,2)).to(devices[0])\n",
    "#net = TACModel(num_hiddens=56, norm_shape=[56], \n",
    "                 ffn_num_input=56, ffn_num_hiddens=128, num_heads=8, num_layers=12, dropout=0.01,\n",
    "                 key_size=56, query_size=56, value_size=56, hid_in_features=56, t_in_features=56).to(devices[0])\n",
    "a = net(X,a)[0]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e6d3e-5e96-40c9-8716-f2779cb5ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b22b823-a4bd-4ccd-ac03-1620396e453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as Data\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from d2l import torch as d2l\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a5f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c655a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_datasets=[]\n",
    "for i in range(8):\n",
    "    dataset_path = f'C:/Users/Administrator/SS_data/dataset/train/traindataset{i}'\n",
    "    tr_datasets += torch.load(dataset_path)\n",
    "tr = tr_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fa7e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7246f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dataset, batch_size):\n",
    "    loader = Data.DataLoader(dataset=dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a18a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = load(tr, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6441fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2457, 54])\n",
      "torch.Size([256, 2457, 54])\n",
      "torch.Size([256, 2457, 54])\n",
      "torch.Size([256, 2457, 54])\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for i in train_iter:\n",
    "    train_list.append(i)\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5826d062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[device(type='cuda', index=0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = d2l.try_all_gpus()\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9267878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TACModel(nn.Module):\n",
    "    def __init__(self, num_hiddens, norm_shape, \n",
    "                 ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 key_size, query_size, value_size,\n",
    "                 t_in_features, hid_in_features):\n",
    "        super(TACModel, self).__init__()\n",
    "        self.acount = AcountExtract()\n",
    "        self.encoder = TACEncoder(num_hiddens, norm_shape, \n",
    "                 ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 key_size, query_size, value_size)    \n",
    "        self.tap = TransiActionPred(t_in_features)\n",
    "        self.tnp = TransiNumberPred(t_in_features)\n",
    "        self.value = ValueNet(t_in_features)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "\n",
    "    def forward(self, x, acount):\n",
    "        Acount  = self.acount(acount)\n",
    "        X = torch.cat((x,Acount), dim=2)\n",
    "        encoded_X = self.encoder(X)\n",
    "        action_hat = self.tap(self.hidden(encoded_X[:, :, -1]))\n",
    "        number_hat = self.tnp(self.hidden(encoded_X[:, :, -1]))\n",
    "        value = self.value(self.hidden(encoded_X[:, :, -1]))\n",
    "        return  action_hat, number_hat, value\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "def transpose_qkv(X, num_heads):\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "        output = self.attention(queries, keys, values)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "    \n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.BatchNorm1d(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "class TACEncoder(nn.Module):\n",
    "    def __init__(self,num_hiddens, norm_shape, \n",
    "                 ffn_num_input,ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 key_size, query_size, value_size,\n",
    "                 **kwargs):\n",
    "        super(TACEncoder, self).__init__(**kwargs)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"{i}\", EncoderBlock(\n",
    "                key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 56, num_hiddens))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.pos_embedding.data[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X)\n",
    "        return X\n",
    "    \n",
    "class TransiActionPred(nn.Module):\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(TransiActionPred, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 3)\n",
    "    def forward(self, X):\n",
    "        return F.softmax(self.output(X), dim=-1)\n",
    "\n",
    "class TransiNumberPred(nn.Module):       #---使用类别优化器，将交易数量拟合为仓位百分比[10%, 50%. 100%]\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(TransiNumberPred, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 3)\n",
    "    def forward(self, X):\n",
    "        return F.softmax(self.output(X), dim=-1)\n",
    "    \n",
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(ValueNet, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 1)\n",
    "    def forward(self, X):\n",
    "        return self.output(X)\n",
    "\n",
    "class AcountExtract(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AcountExtract, self).__init__(**kwargs)\n",
    "        self.expand = nn.Linear(2, 56*2)\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, 1, 2)\n",
    "        X = self.expand(X)\n",
    "        X = X.view(-1, 56, 2)\n",
    "        return X\n",
    "#注意：action和number的多任务分类预测损失函数需改为，两个单独任务的loss加权和，其中权重是超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832069d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv:\n",
    "    def __init__(self):\n",
    "        #初始化参数\n",
    "        self.current_day = 0\n",
    "        self.state_size = (256, 56, 54)\n",
    "        self.position_options = torch.tensor([0.1, 0.5, 1.0])\n",
    "        self.num_stocks = 256\n",
    "\n",
    "        #初始化状态\n",
    "        self.account_balance = torch.full((self.num_stocks,), 10000.0)\n",
    "        self.stock_quantity = torch.zeros(self.num_stocks)\n",
    "        \n",
    "        #定义空间\n",
    "        self.action_space = spaces.Tuple((spaces.Discrete(3), spaces.Discrete(3)))  # 交易行为和交易数量\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, \n",
    "                                            shape=self.state_size, dtype=np.float32)\n",
    "\n",
    "    def load_data(self, data):\n",
    "        if hasattr(self, 'data'):\n",
    "            del self.data\n",
    "        self.data = data\n",
    "        self.total_days = data.shape[1]   #2457天\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        #重置环境状态\n",
    "        self.current_day = 0\n",
    "        self.account_balance.fill_(10000.0)\n",
    "        self.stock_quantity.zero_()\n",
    "\n",
    "    def step(self, trade_actions, position_actions):\n",
    "        #获取当前状态\n",
    "        current_state = self._get_current_state()\n",
    "        #获取当前股价\n",
    "        closing_prices = current_state[:,-1,0]\n",
    "        #计算交易\n",
    "        rewards = torch.zeros(self.num_stocks)\n",
    "        for i in range(self.num_stocks):\n",
    "            closing_price = closing_prices[i]\n",
    "            trade_action = trade_actions[i]\n",
    "            position_action = position_actions[i]\n",
    "            if trade_action == 1:  # 买入\n",
    "                buy_quantity = (self.account_balance[i] * self.position_options[position_action] / closing_price).floor()\n",
    "                if buy_quantity > 0:\n",
    "                    self.account_balance[i] -= buy_quantity * closing_price\n",
    "                    self.stock_quantity[i] += buy_quantity\n",
    "                    income = (self.account_balance[i]+self.stock_quantity[i]*closing_price - 10000)/10000\n",
    "                    rewards[i] = income + 0.1\n",
    "                else:\n",
    "                    rewards[i] = -1       #惩罚不合规交易\n",
    "            elif trade_action == 2:  # 卖出\n",
    "                sell_quantity = (self.position_options[position_action] * self.stock_quantity[i]).floor()\n",
    "                if sell_quantity > 0:\n",
    "                    self.account_balance[i] += sell_quantity * closing_price\n",
    "                    self.stock_quantity[i] -= sell_quantity\n",
    "                    income = (self.account_balance[i]+self.stock_quantity[i]*closing_price - 10000)/10000\n",
    "                    rewards[i] = income + 0.1\n",
    "                else:\n",
    "                    rewards[i] = -1       #惩罚不合规交易\n",
    "            else:  # 不交易\n",
    "                income = (self.account_balance[i]+self.stock_quantity[i]*closing_price - 10000)/10000\n",
    "                rewards[i] = income * 0.5 - 1\n",
    "        # 更新当前交易日\n",
    "        self.current_day += 1\n",
    "        # 检查是否达到游戏结束\n",
    "        done = self.current_day >= self.total_days - self.state_size[1] - 1\n",
    "        next_state = self._get_next_state()\n",
    "        \n",
    "        return next_state, rewards, done, _\n",
    "    \n",
    "    def _get_current_state(self):\n",
    "        return self.data[:, self.current_day:(self.current_day + self.state_size[1]), :]\n",
    "    \n",
    "    def _get_next_state(self):\n",
    "        start = self.current_day\n",
    "        end = start + self.state_size[1]\n",
    "        return self.data[:, start:end, :]\n",
    "    \n",
    "    def get_acount(self):\n",
    "        # 返回当前状态\n",
    "        return torch.stack([self.account_balance, self.stock_quantity], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ef86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMemory:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'reward': [],\n",
    "            'loss': []   }\n",
    "\n",
    "    def add_data(self, reward, loss):\n",
    "        self.data['reward'].append(reward)\n",
    "        self.data['loss'].append(loss)\n",
    "\n",
    "    def reset(self):\n",
    "        for key in self.data.keys():\n",
    "            self.data[key].clear()\n",
    "\n",
    "    def get_data(self, key):\n",
    "        return torch.stack(self.data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a85f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "policynet = TACModel(num_hiddens=56, norm_shape=[56], \n",
    "                 ffn_num_input=56, ffn_num_hiddens=128, num_heads=8, num_layers=12, dropout=0.01,\n",
    "                 key_size=56, query_size=56, value_size=56, hid_in_features=56, t_in_features=56).to(devices[0])\n",
    "pretrained_dict = torch.load(\"Transformer.params\")\n",
    "policynet.load_state_dict(pretrained_dict)\n",
    "optimizer = optim.Adam(policynet.parameters(), lr=0.001)\n",
    "gamma = 0.8\n",
    "datamemory = DataMemory()\n",
    "env = StockTradingEnv()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4051c69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:10632.30\n",
      "loss:-13418.12\n",
      "reward:1712.36\n",
      "loss:-889.54\n",
      "reward:18725.96\n",
      "loss:-3909.14\n",
      "reward:57542.27\n",
      "loss:-3681.47\n"
     ]
    }
   ],
   "source": [
    "act_weight = 0.5\n",
    "num_weight = 0.5\n",
    "num_epoch = 1\n",
    "r_list = []\n",
    "l_list = []\n",
    "for i in range(num_epoch):\n",
    "    for i, state in enumerate(train_iter):\n",
    "        #创建环境\n",
    "        env.load_data(state)\n",
    "        done = False\n",
    "        while not done:\n",
    "            #获得当前环境账户信息\n",
    "            current_acount = (env.get_acount()).to(devices[0]).float()\n",
    "            #获得当前状态空间\n",
    "            current_state = env._get_current_state().float().to(devices[0])\n",
    "            \n",
    "            #进入GPU的net，获得动作空间,value\n",
    "            action_prob, number_prob, value_current = policynet(current_state, current_acount)\n",
    "            #根据概率分布随机抽样动作\n",
    "            action_dist = Categorical(action_prob)          \n",
    "            number_dist = Categorical(number_prob)          \n",
    "            actions = action_dist.sample().detach()                   #(256,1)\n",
    "            numbers = number_dist.sample().detach()                   #(256,1)\n",
    "            #进入CPU的环境交互\n",
    "            next_state, reward, done,_ = env.step(actions.cpu(), numbers.cpu())\n",
    "            reward = reward.to(devices[0]).float()\n",
    "            \n",
    "            #获得下一环境账户信息\n",
    "            next_acount =  (env.get_acount()).to(devices[0]).float()\n",
    "            next_state = next_state.float().to(devices[0])\n",
    "            #获得下一value\n",
    "            _, _, value_next = policynet(next_state, next_acount)\n",
    "            #TD算法\n",
    "            td_error = reward + (gamma * value_next * (1 - int(done))) - value_current\n",
    "            #log动作\n",
    "            act_loss = -torch.log(action_prob[[i for i in range((len(action_prob)))],actions.long()]) * td_error\n",
    "            avg_act_loss = act_loss.mean()\n",
    "            num_loss = -torch.log(number_prob[[i for i in range((len(number_prob)))],numbers.long()]) * td_error\n",
    "            avg_num_loss = num_loss.mean()\n",
    "            #计算加权总损失\n",
    "            total_loss = act_weight * avg_act_loss + num_weight * avg_num_loss\n",
    "            #记录数据\n",
    "            datamemory.add_data(reward.sum(), total_loss)\n",
    "            \n",
    "            #更新\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        r = datamemory.get_data('reward').sum()\n",
    "        l = datamemory.get_data('loss').sum()\n",
    "        r_list.append(r.cpu())\n",
    "        l_list.append(l.cpu())\n",
    "        print(f'reward:{r:.2f}')\n",
    "        print(f'loss:{l:.2f}')\n",
    "        datamemory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c67461-35f1-4dda-9349-b124a93e479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_params = policynet.state_dict()\n",
    "torch.save(transformer_params, \"Transformer.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d55f5d-a63c-4153-95ce-f668ee7e30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./r_list.pkl','wb') as file:\n",
    "    pickle.dump(r_list, file)\n",
    "with open('./l_list.pkl','wb') as file:\n",
    "    pickle.dump(l_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68145d9-efd2-438b-997a-267c4c117bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r_list)\n",
    "plt.title(\"Total Rewards\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
